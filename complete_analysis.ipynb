{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8099957,"sourceType":"datasetVersion","datasetId":4783183}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/akashgpt04011995/complete-analysis-ipynb?scriptVersionId=175020267\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T10:18:35.585325Z","iopub.execute_input":"2024-04-24T10:18:35.585608Z","iopub.status.idle":"2024-04-24T10:18:35.953102Z","shell.execute_reply.started":"2024-04-24T10:18:35.58556Z","shell.execute_reply":"2024-04-24T10:18:35.952148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom collections import Counter\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T10:18:35.974305Z","iopub.execute_input":"2024-04-24T10:18:35.974742Z","iopub.status.idle":"2024-04-24T10:18:36.711957Z","shell.execute_reply.started":"2024-04-24T10:18:35.974714Z","shell.execute_reply":"2024-04-24T10:18:36.711192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# col_names = pd.read_csv('/kaggle/input/data-science-challenge-predicting-stock-trends/column_names_dictionary.csv', sep='delimiter', header=None)\n# print(col_names.shape)\n# col_names = col_names[0].str.split(';', n=2, expand=True)\n# col_names, col_names.columns = col_names[1:] , col_names.iloc[0]\n# col_names.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T10:18:37.466661Z","iopub.execute_input":"2024-04-24T10:18:37.467149Z","iopub.status.idle":"2024-04-24T10:18:37.471345Z","shell.execute_reply.started":"2024-04-24T10:18:37.46712Z","shell.execute_reply":"2024-04-24T10:18:37.470461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Train Data","metadata":{}},{"cell_type":"code","source":"# Fetching data from csv\ntrain_data = pd.read_csv('/kaggle/input/data-science-challenge-predicting-stock-trends/training_data.csv', sep='delimiter', header=None)\nprint(train_data.shape)\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:23.710406Z","iopub.execute_input":"2024-04-24T11:19:23.711147Z","iopub.status.idle":"2024-04-24T11:19:23.783345Z","shell.execute_reply.started":"2024-04-24T11:19:23.711116Z","shell.execute_reply":"2024-04-24T11:19:23.782356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"code","source":"# Transforming into tabular data\ntrain_data= train_data[0].str.split(';', n=160, expand=True)\ntrain_data, train_data.columns = train_data[1:] , train_data.iloc[0]\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:24.076257Z","iopub.execute_input":"2024-04-24T11:19:24.076675Z","iopub.status.idle":"2024-04-24T11:19:24.278313Z","shell.execute_reply.started":"2024-04-24T11:19:24.076641Z","shell.execute_reply":"2024-04-24T11:19:24.277452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing , with .\ntrain_data = pd.DataFrame({col: train_data[col].str.replace(',', '.') for col in train_data.columns})\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:24.588748Z","iopub.execute_input":"2024-04-24T11:19:24.589351Z","iopub.status.idle":"2024-04-24T11:19:25.122097Z","shell.execute_reply.started":"2024-04-24T11:19:24.58932Z","shell.execute_reply":"2024-04-24T11:19:25.121135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert Categorical Feature to Numerical","metadata":{}},{"cell_type":"code","source":"# Convert the Group column to a one hot encoded Data Frame\ndisplay(train_data['Group'].value_counts())\ntrain_data = pd.get_dummies(train_data, columns=['Group'], drop_first=True, prefix='G')\ntrain_data = train_data.replace({False: 0, True: 1})\n# Print the columns names\nprint(train_data.columns)\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:25.673416Z","iopub.execute_input":"2024-04-24T11:19:25.674212Z","iopub.status.idle":"2024-04-24T11:19:26.090938Z","shell.execute_reply.started":"2024-04-24T11:19:25.674179Z","shell.execute_reply":"2024-04-24T11:19:26.089821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop(['Perform'], axis=1)\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:27.748108Z","iopub.execute_input":"2024-04-24T11:19:27.748465Z","iopub.status.idle":"2024-04-24T11:19:27.76623Z","shell.execute_reply.started":"2024-04-24T11:19:27.748435Z","shell.execute_reply":"2024-04-24T11:19:27.765309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train_data.columns:\n    train_data[col] = pd.to_numeric(train_data[col], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:29.015019Z","iopub.execute_input":"2024-04-24T11:19:29.015752Z","iopub.status.idle":"2024-04-24T11:19:29.641Z","shell.execute_reply.started":"2024-04-24T11:19:29.015716Z","shell.execute_reply":"2024-04-24T11:19:29.640218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:30.473023Z","iopub.execute_input":"2024-04-24T11:19:30.473387Z","iopub.status.idle":"2024-04-24T11:19:30.481607Z","shell.execute_reply.started":"2024-04-24T11:19:30.473357Z","shell.execute_reply":"2024-04-24T11:19:30.480625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive Analytics","metadata":{}},{"cell_type":"code","source":"# sns.violinplot(data=train_data, y='I3')\nfor col in train_data.columns[:-10]:\n    plt.figure(figsize=(7,2))\n    q1 = train_data[col].quantile(0.25)\n    q3 = train_data[col].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.7*iqr\n    df = train_data.loc[(train_data[col] >= fence_low) & (train_data[col] <= fence_high)].copy()\n    \n    ax = sns.distplot(df[col], bins=100, kde=False)\n    ax.axvline(x=fence_low, linewidth=1, color='orange', ls='--')\n    ax.axvline(x=fence_high, linewidth=1, color='orange', ls='--')\n    print(df.shape)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T10:33:39.127149Z","iopub.execute_input":"2024-04-24T10:33:39.127796Z","iopub.status.idle":"2024-04-24T10:34:24.815555Z","shell.execute_reply.started":"2024-04-24T10:33:39.127763Z","shell.execute_reply":"2024-04-24T10:34:24.814645Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation","metadata":{}},{"cell_type":"code","source":"correlation_matrix = train_data.corrwith(df[\"Class\"]).sort_values(ascending=False).reset_index() # till 55 and -45\ncorrelation_matrix.tail(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:35.557553Z","iopub.execute_input":"2024-04-24T11:19:35.557944Z","iopub.status.idle":"2024-04-24T11:19:35.642932Z","shell.execute_reply.started":"2024-04-24T11:19:35.557908Z","shell.execute_reply":"2024-04-24T11:19:35.641985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = correlation_matrix[1:55]['index'].tolist() + correlation_matrix[-45:]['index'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:35.749744Z","iopub.execute_input":"2024-04-24T11:19:35.750178Z","iopub.status.idle":"2024-04-24T11:19:35.756084Z","shell.execute_reply.started":"2024-04-24T11:19:35.750145Z","shell.execute_reply":"2024-04-24T11:19:35.754898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handle Outliers","metadata":{}},{"cell_type":"markdown","source":"### Handle Missing Value","metadata":{}},{"cell_type":"code","source":"# Check for NaN counts and Blank Values\ntrain_data = train_data[(train_data != 'NA') & (train_data != '')]\n# train_data[train_data != ''].isna().sum().values\ntrain_data.isna().sum().values","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:38.414895Z","iopub.execute_input":"2024-04-24T11:19:38.415533Z","iopub.status.idle":"2024-04-24T11:19:38.478021Z","shell.execute_reply.started":"2024-04-24T11:19:38.415503Z","shell.execute_reply":"2024-04-24T11:19:38.477046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_with_missing_vals = []\ncol_with_minor_missing_vals = []\n\n# summarize the number of rows with missing values for each column\nfor i in range(train_data.shape[1]):\n    # count number of rows with missing values\n    n_miss = train_data.iloc[:,i].isna().sum()\n    perc = n_miss / train_data.shape[0] * 100\n#     print('> %d, %s Missing: %d (%.2f%%)' % (i, train_data.columns[i], n_miss, perc))\n    if perc >= 1.00:\n        col_with_missing_vals.append(train_data.columns[i])\n    elif perc <1.00 and perc >0.00:\n        col_with_minor_missing_vals.append(train_data.columns[i])\nprint(f'{len(col_with_missing_vals)} out of {len(train_data.columns)} have missing values')\nprint(f'{len(col_with_minor_missing_vals)} out of {len(train_data.columns)} have missing values < 1%')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:02:44.473568Z","iopub.execute_input":"2024-04-24T11:02:44.473937Z","iopub.status.idle":"2024-04-24T11:02:44.510318Z","shell.execute_reply.started":"2024-04-24T11:02:44.47391Z","shell.execute_reply":"2024-04-24T11:02:44.50935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ist iteration, let's drop all nan rows from columns with < 1% missing values\nprint(train_data.shape)\ntrain_data = train_data.dropna(subset=col_with_minor_missing_vals)\nprint(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:41.925485Z","iopub.execute_input":"2024-04-24T11:19:41.92641Z","iopub.status.idle":"2024-04-24T11:19:41.944009Z","shell.execute_reply.started":"2024-04-24T11:19:41.926369Z","shell.execute_reply":"2024-04-24T11:19:41.943009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_with_missing_vals = []\ncol_with_minor_missing_vals = []\n\n# summarize the number of rows with missing values for each column\nfor i in range(train_data.shape[1]):\n    # count number of rows with missing values\n    n_miss = train_data.iloc[:,i].isna().sum()\n    perc = n_miss / train_data.shape[0] * 100\n    print('> %d, %s Missing: %d (%.2f%%)' % (i, train_data.columns[i], n_miss, perc))\n    if perc > 0.00:\n        col_with_missing_vals.append(train_data.columns[i])\nprint(f'{len(col_with_missing_vals)} out of {len(train_data.columns)} have missing values')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:02:45.697775Z","iopub.execute_input":"2024-04-24T11:02:45.698401Z","iopub.status.idle":"2024-04-24T11:02:45.734726Z","shell.execute_reply.started":"2024-04-24T11:02:45.698366Z","shell.execute_reply":"2024-04-24T11:02:45.733717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Techinique 1: Fill Missing Vals Using KNN\n# # split into input and output elements\n# data = train_data.values.copy()\n# ix = [i for i in range(data.shape[1]) if i != 116]\n# X, y = data[:, ix], data[:,116]\n# # print total missing\n# print('Missing: %d' % sum(pd.isna(X).flatten()))\n# # define imputer\n# # imputer = KNNImputer(n_neighbors=3)\n# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n# # fit on the dataset\n# imputer.fit(X)\n# # transform the dataset\n# Xtrans = imputer.transform(X)\n# # print total missing\n# print('Missing: %d' % sum(pd.isna(Xtrans).flatten()))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:03:03.558422Z","iopub.execute_input":"2024-04-24T11:03:03.559038Z","iopub.status.idle":"2024-04-24T11:03:03.565025Z","shell.execute_reply.started":"2024-04-24T11:03:03.559009Z","shell.execute_reply":"2024-04-24T11:03:03.564159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"def add_calculated_columns(X:pd.DataFrame) -> pd.DataFrame:\n    X['profit_ratio'] = np.divide((X['I1'] + X['I2'] + X['I3'] + X['I4']), 4)\n    X['liquidity'] = np.divide((X['I50'] + X['I51'] + X['I53']), 3)\n    X['leverage'] = np.divide((X['I54'] + X['I55'] + X['I56']), 3)\n    X['oper_eff'] = np.divide((X['I22'] + X['I23'] + X['I24'] + X['I25'] + X['I26']), 5)\n    X['valuation'] = np.divide((X['I39'] + X['I40'] + X['I41'] + X['I42'] + X['I43']), 5)\n    return X\ncalculated_columns = ['profit_ratio', 'liquidity', 'leverage', 'oper_eff', 'valuation']","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:48.529899Z","iopub.execute_input":"2024-04-24T11:19:48.530289Z","iopub.status.idle":"2024-04-24T11:19:48.538676Z","shell.execute_reply.started":"2024-04-24T11:19:48.530259Z","shell.execute_reply":"2024-04-24T11:19:48.537559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\ntrain_data = add_calculated_columns(train_data)\nprint(train_data.shape)\ntrain_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:49.460694Z","iopub.execute_input":"2024-04-24T11:19:49.461058Z","iopub.status.idle":"2024-04-24T11:19:49.489061Z","shell.execute_reply.started":"2024-04-24T11:19:49.461028Z","shell.execute_reply":"2024-04-24T11:19:49.488123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:51.651176Z","iopub.execute_input":"2024-04-24T11:19:51.651535Z","iopub.status.idle":"2024-04-24T11:19:51.656708Z","shell.execute_reply.started":"2024-04-24T11:19:51.651504Z","shell.execute_reply":"2024-04-24T11:19:51.655749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # define modeling pipeline\n# # model = RandomForestClassifier(n_estimators=150, max_depth=26, random_state=1111)\n# model = SVC(kernel='rbf')\n# # model = GaussianNB()\n# # model = AdaBoostClassifier()\n# # model = DecisionTreeClassifier()\n# # model = LogisticRegression()\n# # model = lgb.LGBMClassifier() # .477\n\n# # imputer = KNNImputer()\n# pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n# # define model evaluation\n# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# # evaluate model\n# scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n# print('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores))) # .474 # RF & ADB .483 # SVC - .487 # NB - .33 # DT - .41","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # evaluate each strategy on the dataset\n# results = list()\n# strategies = [str(i) for i in [1,3,7,11,15,19]]\n# for s in strategies:\n#     # create the modeling pipeline\n#     pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', SVC(kernel='rbf'))])\n#     # evaluate the model\n#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n#     scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n#     # store results\n#     results.append(scores)\n#     print('>%s %.3f (%.3f)' % (s, np.mean(scores), np.std(scores)))\n# # plot model performance for comparison\n# plt.boxplot(results, labels=strategies, showmeans=True)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # changing data types to float\n# train_data = pd.concat([train_data.iloc[:,0], train_data[train_data.columns[1:]].astype(float)], axis=1)\n# train_data.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting Corr Features Only","metadata":{}},{"cell_type":"code","source":"# Spliting input and target features\n# train_data['Class'] = train_data['Class'].apply(lambda x:2.0 if x==-1.0 else x)\ndisplay(train_data['Class'].value_counts())\n# X = train_data.drop(['Class'], axis=1)\nX = train_data[corr_features+calculated_columns]\ny = train_data['Class'].astype('int')\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:19:56.053251Z","iopub.execute_input":"2024-04-24T11:19:56.054029Z","iopub.status.idle":"2024-04-24T11:19:56.065394Z","shell.execute_reply.started":"2024-04-24T11:19:56.053999Z","shell.execute_reply":"2024-04-24T11:19:56.064448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"# Splitting train and set data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.80, random_state=1111, stratify=y)\nprint(X_train.shape, X_val.shape, y_train.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:01.059635Z","iopub.execute_input":"2024-04-24T11:20:01.059985Z","iopub.status.idle":"2024-04-24T11:20:01.075146Z","shell.execute_reply.started":"2024-04-24T11:20:01.059958Z","shell.execute_reply":"2024-04-24T11:20:01.074329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n# fit on the dataset\nX_train = imputer.fit_transform(X_train)\n# transform the dataset\nX_val = imputer.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:03.551673Z","iopub.execute_input":"2024-04-24T11:20:03.552044Z","iopub.status.idle":"2024-04-24T11:20:03.577804Z","shell.execute_reply.started":"2024-04-24T11:20:03.552013Z","shell.execute_reply":"2024-04-24T11:20:03.57701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handle Imbalance Data","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 21) \nprint(Counter(y_train))\nX_train, y_train = sm.fit_resample(X_train, y_train)\nCounter(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:05.979643Z","iopub.execute_input":"2024-04-24T11:20:05.980299Z","iopub.status.idle":"2024-04-24T11:20:06.040058Z","shell.execute_reply.started":"2024-04-24T11:20:05.980268Z","shell.execute_reply":"2024-04-24T11:20:06.039283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"# Model Fitting\n# Create a random forest classifier\n# model = RandomForestClassifier(n_estimators=150, max_depth=26, random_state=1111)\nmodel = SVC(kernel='rbf')\n# model = lgb.LGBMClassifier()\n# Fit rfc using X_train and y_train\nmodel.fit(X_train, y_train)\n# Create predictions on X_test\npreds = model.predict(X_val)\nprint(preds[0:5])\n# Print model accuracy using score() and the testing data\nprint(model.score(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:16.426062Z","iopub.execute_input":"2024-04-24T11:20:16.426418Z","iopub.status.idle":"2024-04-24T11:20:29.427941Z","shell.execute_reply.started":"2024-04-24T11:20:16.42639Z","shell.execute_reply":"2024-04-24T11:20:29.427034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\npreds = model.predict(X_val)\ncm = confusion_matrix(preds, y_val)\n# ConfusionMatrixDisplay(cm, model.classes_).plot()\ncm","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:29.429499Z","iopub.execute_input":"2024-04-24T11:20:29.429794Z","iopub.status.idle":"2024-04-24T11:20:31.037963Z","shell.execute_reply.started":"2024-04-24T11:20:29.429768Z","shell.execute_reply":"2024-04-24T11:20:31.036972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cost_matrix = [[0,1,2], [1,0,1], [2,1,0]]\ncost_matrix","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:31.039356Z","iopub.execute_input":"2024-04-24T11:20:31.03982Z","iopub.status.idle":"2024-04-24T11:20:31.047152Z","shell.execute_reply.started":"2024-04-24T11:20:31.039787Z","shell.execute_reply":"2024-04-24T11:20:31.046134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cost Calulation","metadata":{}},{"cell_type":"code","source":"err = np.sum((cm*cost_matrix)/len(y_val))\nprint(err)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:31.0493Z","iopub.execute_input":"2024-04-24T11:20:31.04994Z","iopub.status.idle":"2024-04-24T11:20:31.058026Z","shell.execute_reply.started":"2024-04-24T11:20:31.049898Z","shell.execute_reply":"2024-04-24T11:20:31.057055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### defining the model \n# import xgboost as xgb\n# from xgboost import XGBClassifier\n# model=xgb.XGBClassifier(n_estimators=1000, learning_rate=0.05, tree_method = 'gpu_hist',min_child_weight=5, reg_lambda=20, gamma=2 ,random_state=69,\n#                        reg_alpha=26,subsample=0.9,colsample_bytree=0.12,max_depth=30)\n# # Fit rfc using X_train and y_train\n# model.fit(X_train, y_train)\n# # Create predictions on X_test\n# preds = model.predict(X_val)\n# print(preds[0:5])\n# # Print model accuracy using score() and the testing data\n# print(model.score(X_val, y_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on Test Data","metadata":{}},{"cell_type":"code","source":"# Fetching data from csv\ntest_data = pd.read_csv('/kaggle/input/data-science-challenge-predicting-stock-trends/test_data_no_target.csv', sep='delimiter', header=None)\nprint(test_data.shape)\ntest_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:47.259417Z","iopub.execute_input":"2024-04-24T11:20:47.260267Z","iopub.status.idle":"2024-04-24T11:20:47.28888Z","shell.execute_reply.started":"2024-04-24T11:20:47.260232Z","shell.execute_reply":"2024-04-24T11:20:47.287943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming into tabular data\ntest_data= test_data[0].str.split(';', n=160, expand=True)\ntest_data, test_data.columns = test_data[1:] , test_data.iloc[0]\ntest_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:47.606749Z","iopub.execute_input":"2024-04-24T11:20:47.607131Z","iopub.status.idle":"2024-04-24T11:20:47.666727Z","shell.execute_reply.started":"2024-04-24T11:20:47.6071Z","shell.execute_reply":"2024-04-24T11:20:47.665781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing , with .\ntest_data = pd.DataFrame({col: test_data[col].str.replace(',', '.') for col in test_data.columns})\ntest_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:47.874687Z","iopub.execute_input":"2024-04-24T11:20:47.875374Z","iopub.status.idle":"2024-04-24T11:20:48.059481Z","shell.execute_reply.started":"2024-04-24T11:20:47.875339Z","shell.execute_reply":"2024-04-24T11:20:48.058521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.get_dummies(test_data, columns=['Group'], drop_first=True, prefix='G')\ntest_data = test_data.replace({False: 0, True: 1})","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:48.122675Z","iopub.execute_input":"2024-04-24T11:20:48.123375Z","iopub.status.idle":"2024-04-24T11:20:48.215183Z","shell.execute_reply.started":"2024-04-24T11:20:48.123344Z","shell.execute_reply":"2024-04-24T11:20:48.214114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in test_data.columns:\n    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\nprint(test_data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:48.362503Z","iopub.execute_input":"2024-04-24T11:20:48.362912Z","iopub.status.idle":"2024-04-24T11:20:48.554912Z","shell.execute_reply.started":"2024-04-24T11:20:48.362881Z","shell.execute_reply":"2024-04-24T11:20:48.553937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for NaN counts and Blank Values\ntest_data = test_data[(test_data != 'NA') & (test_data != '')]\n# train_data[train_data != ''].isna().sum().values\ntest_data.isna().sum().values","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:48.770721Z","iopub.execute_input":"2024-04-24T11:20:48.771301Z","iopub.status.idle":"2024-04-24T11:20:48.826592Z","shell.execute_reply.started":"2024-04-24T11:20:48.771271Z","shell.execute_reply":"2024-04-24T11:20:48.825645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = add_calculated_columns(test_data)\nprint(test_data.shape)\ntest_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:49.65877Z","iopub.execute_input":"2024-04-24T11:20:49.65915Z","iopub.status.idle":"2024-04-24T11:20:49.690034Z","shell.execute_reply.started":"2024-04-24T11:20:49.65912Z","shell.execute_reply":"2024-04-24T11:20:49.689153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_data[corr_features+calculated_columns]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:50.398673Z","iopub.execute_input":"2024-04-24T11:20:50.399502Z","iopub.status.idle":"2024-04-24T11:20:50.41057Z","shell.execute_reply.started":"2024-04-24T11:20:50.399461Z","shell.execute_reply":"2024-04-24T11:20:50.409618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform the dataset\nX_test = imputer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:20:52.638903Z","iopub.execute_input":"2024-04-24T11:20:52.639673Z","iopub.status.idle":"2024-04-24T11:20:52.652206Z","shell.execute_reply.started":"2024-04-24T11:20:52.639638Z","shell.execute_reply":"2024-04-24T11:20:52.651314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(X_test)\nprint(test_preds[:5])\nprint(test_preds.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:23:03.554166Z","iopub.execute_input":"2024-04-24T11:23:03.554534Z","iopub.status.idle":"2024-04-24T11:23:05.58237Z","shell.execute_reply.started":"2024-04-24T11:23:03.554505Z","shell.execute_reply":"2024-04-24T11:23:05.581376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(test_preds).to_csv('test_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T11:24:13.120466Z","iopub.execute_input":"2024-04-24T11:24:13.120875Z","iopub.status.idle":"2024-04-24T11:24:13.130668Z","shell.execute_reply.started":"2024-04-24T11:24:13.120844Z","shell.execute_reply":"2024-04-24T11:24:13.129639Z"},"trusted":true},"execution_count":null,"outputs":[]}]}